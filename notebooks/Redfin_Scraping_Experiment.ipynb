{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2eab31-6e4e-4275-a0ad-063571ec7372",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Scrape property listings from Redfin.com and extract a range of essential details, including prices, addresses, beds/baths, images, and geo-coordinates.\n",
    "\n",
    "## Target URL\n",
    "\n",
    "https://www.redfin.com/neighborhood/547223/CA/Los-Angeles/Hollywood-Hills\n",
    "\n",
    "## Approach\n",
    "\n",
    "- Check if site is static or dynamically generated\n",
    "- Methodically identify and bypass anti-bot techniques\n",
    "- Identify and parse relevant page elements for the data points in the first listing\n",
    "- Put everything together- Loop through listings in the first page and create a dataframe from the listings\n",
    "- Extend the script to cover multiple pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3eb7a-6d34-4d56-a335-b3f55e4a95a0",
   "metadata": {},
   "source": [
    "## Determine whether the site is static or dynamically generated, and identify anti-bot techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c9314-400e-42be-b923-9ecb8ff24717",
   "metadata": {},
   "source": [
    "Typical symptoms of bot detection:\n",
    "- 403 Forbidden\n",
    "- Empty response or \"Access Denied\"\n",
    "- CAPTCHA pages\n",
    "- Meta refresh or JavaScript redirection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f22c3e-800f-4323-9b24-bf0b061c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4342fcd8-2a06-459d-ae88-577e0cdee194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redfin search URL for Hollywood Hills, Los Angeles\n",
    "base_url = \"https://www.redfin.com/neighborhood/547223/CA/Los-Angeles/Hollywood-Hills\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5bb5e-0a2c-42b8-a9f2-2f519a48c92b",
   "metadata": {},
   "source": [
    "## Testing requests without headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c32dcb1-e227-47f0-b880-fb2dac6e7001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "<!doctype html>\n",
      "<html>\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>Are You a Robot? | Redfin</title>\n",
      "    <style>\n",
      "        body {\n",
      "            font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "            margin: 0;\n",
      "            text-align: left;\n",
      "            font-size: 16px;\n",
      "            color: #333;\n",
      "        }\n",
      "\n",
      "        #header {\n",
      "            min-width: 300px;\n",
      "            height: 60px;\n",
      "            width: 100%;\n",
      "            background-color: #fff;\n",
      "        }\n",
      "\n",
      "        #header .logo {\n",
      "         \n"
     ]
    }
   ],
   "source": [
    "r = requests.get(base_url)\n",
    "print(r.status_code)\n",
    "print(r.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadadca7-c6b9-4ef7-805e-b52f28f4d706",
   "metadata": {},
   "source": [
    "Status code: 429 suggests 'requests without headers' won't fly. Some anti-bot symptom?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e1f3c-e4af-409a-998b-a96d713caf4e",
   "metadata": {},
   "source": [
    "## Capture headers from live browsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151abd1-392c-449f-9e65-23e9aed6e064",
   "metadata": {},
   "source": [
    "- Visit target URL\n",
    "- Open the Network tab in the DevTools\n",
    "- Right click (or Ctrl-click) a request\n",
    "- Click \"Copy\" → \"Copy as cURL(bash)\"\n",
    "- You can now paste it in the relevant curl converter (e.g. https://curlconverter.com/) to translate it in the language you want - in our case, python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c4a3a3-d012-46c7-9818-d6cca279d353",
   "metadata": {},
   "source": [
    "## Testing requests with captured headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1175b4-47c3-4559-9d06-7014edddf215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html><html lang=\"en\"><head>\n",
      "\t\t<script src=\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\"  type=\"text/javascript\" charset=\"UTF-8\" data-domain-script=\"7e5bc3d6-ef20-4760-aa0d-c8df4649fae2\" ></script>\n",
      "\t\t\n",
      "\t\t<script>\n",
      "\t\t\twindow.__uspapi = function (command, version, callback) {\n",
      "\t\t\t\tcallback({}, false);\n",
      "\t\t\t}\n",
      "\t\t</script>\n",
      "\t\n",
      "\t<!-- Server: customer-pages-map-dp --><!-- Time generated: Sun Jul 27 2025 21:20:24 GMT+0000 (Coordinated Universal Time) --><script>(function(a){window.__reactSe\n"
     ]
    }
   ],
   "source": [
    "# copy the python request header from the curl converter\n",
    "\n",
    "headers = {\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'Referer': 'https://www.redfin.com/',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',\n",
    "    'sec-ch-ua': '\"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"138\", \"Google Chrome\";v=\"138\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "}\n",
    "\n",
    "r = requests.get(base_url, headers=headers)\n",
    "print(r.status_code)\n",
    "print(r.text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd684915-cd6b-4e97-89f2-e8191cde2bf0",
   "metadata": {},
   "source": [
    "Ok, status code returns 200, but the page appears to be dynamically generated. React app?\n",
    "\n",
    "If the data we need is loaded dynamically via JavaScript, standard scraping methods won’t work. Selenium can load the page and execute JavaScript, allowing us to scrape the rendered content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208d42a-4859-45c3-97b5-3d770d35b93d",
   "metadata": {},
   "source": [
    "## Exploratory scraping with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5556d7a1-054f-48ec-9e5a-564a6738f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import selenium and related libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701b8916-e14a-4a77-83af-2df6180ebdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to set up selenium\n",
    "def init_chrome_driver():\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\" - headless\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39186ec6-1461-4313-99d8-1b5d86ca078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redfin search URL for Hollywood Hills, Los Angeles\n",
    "base_url = \"https://www.redfin.com/neighborhood/547223/CA/Los-Angeles/Hollywood-Hills\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba2c7a2-cc7e-4416-9ec2-442617034700",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = init_chrome_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739ad02-1af1-46d7-a64d-f4a79271bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the website\n",
    "driver.get(base_url)\n",
    "\n",
    "# Let the page load completely\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Get the page source after JavaScript has been executed\n",
    "html = driver.page_source\n",
    "\n",
    "# Parse with BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "print(soup.title.string)\n",
    "print()\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97486809-70ca-486a-810e-c30a4d9cb5d7",
   "metadata": {},
   "source": [
    "An important part of building a web scraping tool is navigating through the source code of the web page we are scraping. The chunk of text above is just a part of the whole page. We may go through it to find the position of the main listings container. Alternatively, we can visit the page live and visually identify where the listings of interest start, right click the area and select inspect or Ctrl+Shift+I to view the CSS elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7526be-4df9-4803-bbbc-73bb6dd0a70f",
   "metadata": {},
   "source": [
    "### Find the data points in the first listing\n",
    "\n",
    "Let's find data for the first listing in the page before looping over the rest to find results of the entire first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca9a8634-46b6-459b-8ada-4147a5044939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 listings on the page\n"
     ]
    }
   ],
   "source": [
    "driver.get(base_url)\n",
    "time.sleep(random.uniform(5, 8))\n",
    "\n",
    "# Locate the main listings container\n",
    "try:\n",
    "    container = driver.find_element(\"css selector\", \"div.HomeCardsContainer\")\n",
    "    listings = container.find_elements(\"css selector\", \"div.HomeCardContainer\")\n",
    "    print(f\"Found {len(listings)} listings on the page\")\n",
    "except:\n",
    "    print(\"Failed to locate the property list container. Exiting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8025fe4-124a-424d-9353-60cecd463423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract price\n",
    "try:\n",
    "    price = listings[0].find_element(\"css selector\", \"span.bp-Homecard__Price--value\").text.strip()\n",
    "except:\n",
    "    price = \"N/A\"\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ddbb9f-86f5-45b5-a18c-9c3184524e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract address\n",
    "try:\n",
    "    address = listings[0].find_element(\"css selector\", \"div.bp-Homecard__Address\").text.strip()\n",
    "    print(address)\n",
    "except:\n",
    "    print(\"Skipping a listing due to missing address data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a9224-2860-4aad-8cb1-6f951da92385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract beds\n",
    "try:\n",
    "    beds = listings[0].find_element(\"css selector\", \"span.bp-Homecard__Stats--beds\").text.strip()\n",
    "except:\n",
    "    beds = \"N/A\"\n",
    "print(beds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721d3ab-5a28-4ca8-ac55-0da8b1fc7719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract baths\n",
    "try:\n",
    "    baths = listings[0].find_element(\"css selector\", \"span.bp-Homecard__Stats--baths\").text.strip()\n",
    "except:\n",
    "    baths = \"N/A\"\n",
    "print(baths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26b7a8-7bbe-434b-aed9-74f1feeba580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sqft\n",
    "try:\n",
    "    sqft = listings[0].find_element(\"css selector\", \"span.bp-Homecard__LockedStat--value\").text.strip()\n",
    "except:\n",
    "    sqft = \"N/A\"\n",
    "print(sqft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a662a-00ba-471c-b2d9-c6ea4b6b42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract listing link\n",
    "try:\n",
    "    link = listings[0].find_element(\"css selector\", \"a.bp-Homecard\").get_attribute(\"href\")\n",
    "    link = f\"https://www.redfin.com{link}\" if link.startswith(\"/\") else link\n",
    "    print(link)\n",
    "    \n",
    "    # Extract ID after /home/\n",
    "    match = re.search(r'/home/(\\d+)', link)\n",
    "    if match:\n",
    "        listing_id = match.group(1)\n",
    "        print(\"🏠 Listing ID:\", listing_id)\n",
    "    else:\n",
    "        print(\"❌ Listing ID not found\")\n",
    "        \n",
    "except:\n",
    "    print(\"Skipping a listing due to missing link data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac015e-bab6-497a-b5d3-4343cacf0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image URL\n",
    "try:\n",
    "    image_element = listings[0].find_element(\"css selector\", \"img.bp-Homecard__Photo--image\")\n",
    "    image_url = image_element.get_attribute(\"src\")\n",
    "except:\n",
    "    image_url = \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fed50-a7e5-41b5-b3c8-4840be36e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Extract Geo-Coordinates (Latitude & Longitude)\n",
    "    json_script = listings[0].find_element(By.CSS_SELECTOR, \"script[type='application/ld+json']\").get_attribute(\"innerHTML\")\n",
    "    json_data = json.loads(json_script)\n",
    "\n",
    "    # Sometimes it's a dict, sometimes a list of dicts\n",
    "    if isinstance(json_data, list):\n",
    "        geo_data = next((item.get(\"geo\") for item in json_data if item.get(\"geo\")), None)\n",
    "    else:\n",
    "        geo_data = json_data.get(\"geo\")\n",
    "\n",
    "    if geo_data:\n",
    "        latitude = geo_data.get(\"latitude\", \"N/A\")\n",
    "        longitude = geo_data.get(\"longitude\", \"N/A\")\n",
    "    else:\n",
    "        latitude = \"N/A\"\n",
    "        longitude = \"N/A\"\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to extract geo-coordinates: {e}\")\n",
    "    latitude = \"N/A\"\n",
    "    longitude = \"N/A\"\n",
    "print(f\"Latitude: {latitude} Longitude:{longitude}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c56e7-7dee-44c6-9deb-d62c8da46ce2",
   "metadata": {},
   "source": [
    "### Put everything together- Loop through results and append data inside a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808f79e-0370-4628-ab2b-e3149fbd7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage\n",
    "redfin_data = []\n",
    "\n",
    "for listing in listings:\n",
    "    # Extract price\n",
    "    try:\n",
    "        price = listing.find_element(\"css selector\", \"span.bp-Homecard__Price--value\").text.strip()\n",
    "    except:\n",
    "        price = \"N/A\"\n",
    "\n",
    "    # Extract address\n",
    "    try:\n",
    "        address = listing.find_element(\"css selector\", \"div.bp-Homecard__Address\").text.strip()\n",
    "    except:\n",
    "        print(\"Skipping a listing due to missing address data\")\n",
    "        continue  # Skip listings with missing elements\n",
    "\n",
    "    # Extract beds, baths, and sqft\n",
    "    try:\n",
    "        beds = listing.find_element(\"css selector\", \"span.bp-Homecard__Stats--beds\").text.strip()\n",
    "    except:\n",
    "        beds = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        baths = listing.find_element(\"css selector\", \"span.bp-Homecard__Stats--baths\").text.strip()\n",
    "    except:\n",
    "        baths = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        sqft = listing.find_element(\"css selector\", \"span.bp-Homecard__LockedStat--value\").text.strip()\n",
    "    except:\n",
    "        sqft = \"N/A\"\n",
    "\n",
    "    # Extract listing link\n",
    "    try:\n",
    "        link = listing.find_element(\"css selector\", \"a.bp-Homecard\").get_attribute(\"href\")\n",
    "        link = f\"https://www.redfin.com{link}\" if link.startswith(\"/\") else link\n",
    "\n",
    "        # Extract ID after /home/\n",
    "        match = re.search(r'/home/(\\d+)', link)\n",
    "        if match:\n",
    "            listing_id = match.group(1)\n",
    "        else:\n",
    "            listing_id = \"N/A\"\n",
    "\n",
    "    except:\n",
    "        print(\"Skipping a listing due to missing link data\")\n",
    "        continue  # Skip listings with missing elements\n",
    "\n",
    "    # Extract image URL\n",
    "    try:\n",
    "        image_element = listing.find_element(\"css selector\", \"img.bp-Homecard__Photo--image\")\n",
    "        image_url = image_element.get_attribute(\"src\")\n",
    "    except:\n",
    "        image_url = \"N/A\"\n",
    "    \n",
    "    try:\n",
    "        # Extract Geo-Coordinates (Latitude & Longitude)\n",
    "        json_script = listing.find_element(By.CSS_SELECTOR, \"script[type='application/ld+json']\").get_attribute(\"innerHTML\")\n",
    "        json_data = json.loads(json_script)\n",
    "\n",
    "        # Sometimes it's a dict, sometimes a list of dicts\n",
    "        if isinstance(json_data, list):\n",
    "            geo_data = next((item.get(\"geo\") for item in json_data if item.get(\"geo\")), None)\n",
    "        else:\n",
    "            geo_data = json_data.get(\"geo\")\n",
    "\n",
    "        if geo_data:\n",
    "            latitude = geo_data.get(\"latitude\", \"N/A\")\n",
    "            longitude = geo_data.get(\"longitude\", \"N/A\")\n",
    "        else:\n",
    "            latitude = \"N/A\"\n",
    "            longitude = \"N/A\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to extract geo-coordinates: {e}\")\n",
    "        latitude = \"N/A\"\n",
    "        longitude = \"N/A\"\n",
    "\n",
    "    # Store the data\n",
    "    redfin_data.append({\n",
    "        \"Listing ID\": listing_id,\n",
    "        \"Price\": price,\n",
    "        \"Address\": address,\n",
    "        \"Beds\": beds,\n",
    "        \"Baths\": baths,\n",
    "        \"SqFt\": sqft,\n",
    "        \"Link\": link,\n",
    "        \"Image URL\": image_url, \n",
    "        \"Latitude\": latitude,\n",
    "        \"Longitude\": longitude\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06509ec3-f8c4-4d48-b6b5-ecd5bc72a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pandas dataframe from the scraped page\n",
    "df_redfin  = pd.DataFrame(redfin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dac4a7-3568-488d-bce9-8ee863c3d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redfin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948dc563-f625-4788-9145-b2570207c44d",
   "metadata": {},
   "source": [
    "### Multiple Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05719d-9198-453b-b14e-8878b5b643c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage\n",
    "redfin_data = []\n",
    "\n",
    "# looping through 5 pages using for loop\n",
    "page_number = 1\n",
    "for i in range(1,6):\n",
    "    print(f\"Scraping page {page_number}...\")\n",
    "\n",
    "    url = base_url if page_number == 1 else f\"{base_url}/page-{page_number}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(random.uniform(5, 8))\n",
    "\n",
    "    # Locate the main listings container\n",
    "    try:\n",
    "        container = driver.find_element(\"css selector\", \"div.HomeCardsContainer\")\n",
    "        listings = container.find_elements(\"css selector\", \"div.HomeCardContainer\")\n",
    "    except:\n",
    "        print(\"Failed to locate the property list container. Exiting...\")\n",
    "        break\n",
    "\n",
    "    print(f\"Found {len(listings)} listings on page {page_number}\")\n",
    "\n",
    "    for listing in listings:\n",
    "        # Extract price\n",
    "        try:\n",
    "            price = listing.find_element(\"css selector\", \"span.bp-Homecard__Price--value\").text.strip()\n",
    "        except:\n",
    "            price = \"N/A\"\n",
    "    \n",
    "        # Extract address\n",
    "        try:\n",
    "            address = listing.find_element(\"css selector\", \"div.bp-Homecard__Address\").text.strip()\n",
    "        except:\n",
    "            print(\"Skipping a listing due to missing address data\")\n",
    "            continue  # Skip listings with missing elements\n",
    "    \n",
    "        # Extract beds, baths, and sqft\n",
    "        try:\n",
    "            beds = listing.find_element(\"css selector\", \"span.bp-Homecard__Stats--beds\").text.strip()\n",
    "        except:\n",
    "            beds = \"N/A\"\n",
    "    \n",
    "        try:\n",
    "            baths = listing.find_element(\"css selector\", \"span.bp-Homecard__Stats--baths\").text.strip()\n",
    "        except:\n",
    "            baths = \"N/A\"\n",
    "\n",
    "        try:\n",
    "            sqft = listing.find_element(\"css selector\", \"span.bp-Homecard__LockedStat--value\").text.strip()\n",
    "        except:\n",
    "            sqft = \"N/A\"\n",
    "    \n",
    "        # Extract listing link and listing id\n",
    "        try:\n",
    "            link = listing.find_element(\"css selector\", \"a.bp-Homecard\").get_attribute(\"href\")\n",
    "            link = f\"https://www.redfin.com{link}\" if link.startswith(\"/\") else link\n",
    "    \n",
    "            # Extract ID after /home/\n",
    "            match = re.search(r'/home/(\\d+)', link)\n",
    "            if match:\n",
    "                listing_id = match.group(1)\n",
    "            else:\n",
    "                listing_id = \"N/A\"\n",
    "    \n",
    "        except:\n",
    "            print(\"Skipping a listing due to missing link data\")\n",
    "            continue  # Skip listings with missing elements\n",
    "\n",
    "        # Extract image URL\n",
    "        try:\n",
    "            image_element = listing.find_element(\"css selector\", \"img.bp-Homecard__Photo--image\")\n",
    "            image_url = image_element.get_attribute(\"src\")\n",
    "        except:\n",
    "            image_url = \"N/A\"\n",
    "    \n",
    "        try:\n",
    "            # Extract Geo-Coordinates (Latitude & Longitude)\n",
    "            json_script = listing.find_element(By.CSS_SELECTOR, \"script[type='application/ld+json']\").get_attribute(\"innerHTML\")\n",
    "            json_data = json.loads(json_script)\n",
    "    \n",
    "            # Sometimes it's a dict, sometimes a list of dicts\n",
    "            if isinstance(json_data, list):\n",
    "                geo_data = next((item.get(\"geo\") for item in json_data if item.get(\"geo\")), None)\n",
    "            else:\n",
    "                geo_data = json_data.get(\"geo\")\n",
    "    \n",
    "            if geo_data:\n",
    "                latitude = geo_data.get(\"latitude\", \"N/A\")\n",
    "                longitude = geo_data.get(\"longitude\", \"N/A\")\n",
    "            else:\n",
    "                latitude = \"N/A\"\n",
    "                longitude = \"N/A\"\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to extract geo-coordinates: {e}\")\n",
    "            latitude = \"N/A\"\n",
    "            longitude = \"N/A\"\n",
    "\n",
    "        # Store the data\n",
    "        redfin_data.append({\n",
    "            \"Listing ID\": listing_id,\n",
    "            \"Price\": price,\n",
    "            \"Address\": address,\n",
    "            \"Beds\": beds,\n",
    "            \"Baths\": baths,\n",
    "            \"SqFt\": sqft,\n",
    "            \"Link\": link,\n",
    "            \"Image URL\": image_url, \n",
    "            \"Latitude\": latitude,\n",
    "            \"Longitude\": longitude\n",
    "        })\n",
    "    \n",
    "\n",
    "    # Try going to the next page by checking if the next-page anchor exists\n",
    "    try:\n",
    "        next_page_anchor = driver.find_element(By.CSS_SELECTOR, \"a[aria-label='page {}']\".format(page_number + 1))\n",
    "        if next_page_anchor:\n",
    "            page_number += 1\n",
    "            time.sleep(random.uniform(3, 6))\n",
    "        else:\n",
    "            break\n",
    "    except:\n",
    "        print(\"✅ No more pages.\")\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969b890-ee66-4b2b-b130-5e4ca3d3ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating pandas dataframe from the scraped pages\n",
    "df_redfin  = pd.DataFrame(redfin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def27a98-5066-4e04-b1ad-948bfb9c4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_redfin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb45e83-7e37-43bc-89ce-e349bb4eef84",
   "metadata": {},
   "source": [
    "### Close the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f8d3b1a-a95a-41e5-91f7-75f30a8ff832",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9cb095-d689-4636-a6a2-b98c1790ef30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
